{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Project",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDF5TVFPob31"
      },
      "source": [
        "#database https://github.com/wkzs111/phm-ieee-2012-data-challenge-dataset/tree/master/Learning_set/Bearing1_1\n",
        "#imported all the libraries reqeuired in the code\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6j1PyOH2931"
      },
      "source": [
        "#define a normalise functioon according to formula given in research paper\n",
        "def norm(list):\n",
        "  mini = min(list)\n",
        "  maxi = max(list)\n",
        "  for i in range(len(list)):\n",
        "    list[i] = 0.1 + (0.8*(list[i]-mini))/(maxi - mini)\n",
        "def normalise(list_1, list_2, list_3):\n",
        "  norm(list_1)\n",
        "  norm(list_2)\n",
        "  norm(list_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsdN0Ogi2qDW"
      },
      "source": [
        "def calculate(rul, rms, amplitude, sizes, learning_bearing, number, something):\n",
        "  print(something)\n",
        "  for i in range(len(learning_bearing)):\n",
        "    if((something == \"Test_set\" and i>1) or something==\"Learning_set\"):\n",
        "      k=pd.read_csv(\"https://raw.githubusercontent.com/wkzs111/phm-ieee-2012-data-challenge-dataset/master/\" + something + \"/Bearing\" + \"{:01d}\".format(number) + \"_\" + \"{:01d}\".format(i+1) + \"/acc_0\"+\"{:04d}\".format(learning_bearing[i]-1)+\".csv\", header=None)\n",
        "\n",
        "      finalTime = (k.iloc[-1][0]*3600) + (k.iloc[-1][1]*60) + k.iloc[-1][2]\n",
        "\n",
        "      for j in range(1, learning_bearing[i]):\n",
        "        f=pd.read_csv(\"https://raw.githubusercontent.com/wkzs111/phm-ieee-2012-data-challenge-dataset/master/\" + something +\"/Bearing\" + \"{:01d}\".format(number) + \"_\" + \"{:01d}\".format(i+1) + \"/acc_0\"+\"{:04d}\".format(j)+\".csv\", names = [\"hr\", \"min\", \"sec\", \"msec\", \"horacc\", \"veracc\"])\n",
        "\n",
        "        #rul\n",
        "        currentTime = (f.iloc[-1][0]*3600) + (f.iloc[-1][1]*60) + f.iloc[-1][2]\n",
        "        rul.append(finalTime - currentTime)\n",
        "\n",
        "        # #RMS\n",
        "        currAcceleration = f.iloc[:, [4]]\n",
        "        MSE = np.square(currAcceleration).mean() \n",
        "        RMSE = math.sqrt(MSE)\n",
        "        rms.append(RMSE)\n",
        "\n",
        "        #Amplitude\n",
        "        AMPL = math.sqrt(2)*(RMSE)\n",
        "        amplitude.append(AMPL)\n",
        "\n",
        "        #size\n",
        "        sizes.append(k.size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-8zK12W2uZx",
        "outputId": "380a55aa-e776-4ea6-d1f5-9b097727fac7"
      },
      "source": [
        "new_rms = []\n",
        "new_amplitude = []\n",
        "new_sizes = []\n",
        "new_rul = []\n",
        "\n",
        "# learning_bearing_1 = [2804, 872]\n",
        "learning_bearing_1 = [2804]\n",
        "learning_bearing_2 = [912, 798]\n",
        "learning_bearing_3 = [516, 1638]\n",
        "# testing_bearing_1 = [0, 0, 1803, 1140, 2303, 2303, 1503]\n",
        "# testing_bearing_2 = [0, 0, 572, 172, 1203, 613, 2003, 573] #from 6 to 7\n",
        "testing_bearing_3 = [0, 0, 353]\n",
        "\n",
        "calculate(new_rul, new_rms, new_amplitude, new_sizes, learning_bearing_1, 1, \"Learning_set\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning_set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tATolIw2q2RU"
      },
      "source": [
        "  #call normalise on all the lists\n",
        "normalise(new_rul, new_amplitude, new_rms)\n",
        "\n",
        "#create dataframe using obtained normalised lists\n",
        "df = pd.DataFrame(list(zip(new_rms, new_amplitude, new_rul)), columns =['RMS', 'Amplitude', 'RUL'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo8k_uNG6qxc"
      },
      "source": [
        "# testing_new_rms = []\n",
        "# testing_new_amplitude = []\n",
        "# testing_new_sizes = []\n",
        "# testing_new_rul = []\n",
        "# print(len(testing_bearing_3))\n",
        "# calculate(testing_new_rul, testing_new_rms, testing_new_amplitude, testing_new_sizes, testing_bearing_3, 3, \"Test_set\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgMFCjvWB1V4"
      },
      "source": [
        "#call normalise on all the lists\n",
        "# normalise(testing_new_rul, testing_new_amplitude, testing_new_rms)\n",
        "#\n",
        "#create dataframe using obtained normalised lists\n",
        "# dfp = pd.DataFrame(list(zip(testing_new_rms, testing_new_amplitude, testing_new_rul)), columns =['RMS', 'Amplitude', 'RUL'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOuKd_ol5TfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d1bb8b5-04a2-4f0a-8200-f5fa1ff95899"
      },
      "source": [
        "# separate into input and output columns\n",
        "# X_train, y_train = df.iloc[:, :-1], df.iloc[:, -1]\n",
        "# X_test, y_test = dfp.iloc[:, :-1], dfp.iloc[:, -1]\n",
        "X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=51)\n",
        "# model = SVR(kernel = 'linear',epsilon=0.1,gamma=0.5,)\n",
        "# model.fit(X, y)\n",
        "# model.score(X_test, y_test)\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=51)\n",
        "# model = SVR(kernel = 'poly',epsilon=0.1,gamma=0.5,)\n",
        "# model.fit(X, y)\n",
        "# model.score(X_test, y_test)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=51)\n",
        "model = SVR(kernel = 'rbf',epsilon=0.1,gamma=0.5,)\n",
        "model.fit(X, y)\n",
        "model.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7531883107908555"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiB6HvF032nZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}